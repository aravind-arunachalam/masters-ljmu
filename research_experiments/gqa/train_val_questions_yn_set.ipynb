{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430536\n"
     ]
    }
   ],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_0.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    if train_all_questions_json[question_key]['answer'].lower() == 'no' or train_all_questions_json[question_key]['answer'].lower() == 'yes':\n",
    "        train_all_questions_dict['question_key'] = question_key\n",
    "        #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "        #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "        train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "        train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "        #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "        train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    \n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_0.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430536\n"
     ]
    }
   ],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_1.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    if train_all_questions_json[question_key]['answer'].lower() == 'no' or train_all_questions_json[question_key]['answer'].lower() == 'yes':\n",
    "        train_all_questions_dict['question_key'] = question_key\n",
    "        #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "        #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "        train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "        train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "        #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "        train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_1.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430536\n"
     ]
    }
   ],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_2.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    if train_all_questions_json[question_key]['answer'].lower() == 'no' or train_all_questions_json[question_key]['answer'].lower() == 'yes':\n",
    "        train_all_questions_dict['question_key'] = question_key\n",
    "        #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "        #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "        train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "        train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "        #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "        train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_2.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430536\n"
     ]
    }
   ],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_3.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    if train_all_questions_json[question_key]['answer'].lower() == 'no' or train_all_questions_json[question_key]['answer'].lower() == 'yes':\n",
    "        train_all_questions_dict['question_key'] = question_key\n",
    "        #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "        #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "        train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "        train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "        #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "        train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_3.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430536\n"
     ]
    }
   ],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_4.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    if train_all_questions_json[question_key]['answer'].lower() == 'no' or train_all_questions_json[question_key]['answer'].lower() == 'yes':\n",
    "        train_all_questions_dict['question_key'] = question_key\n",
    "        #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "        #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "        train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "        train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "        #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "        train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_4.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430536\n"
     ]
    }
   ],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_5.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    if train_all_questions_json[question_key]['answer'].lower() == 'no' or train_all_questions_json[question_key]['answer'].lower() == 'yes':\n",
    "        train_all_questions_dict['question_key'] = question_key\n",
    "        #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "        #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "        train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "        train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "        #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "        train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_5.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430536\n"
     ]
    }
   ],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_6.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    if train_all_questions_json[question_key]['answer'].lower() == 'no' or train_all_questions_json[question_key]['answer'].lower() == 'yes':\n",
    "        train_all_questions_dict['question_key'] = question_key\n",
    "        #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "        #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "        train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "        train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "        #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "        train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_6.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430536\n"
     ]
    }
   ],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_7.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    if train_all_questions_json[question_key]['answer'].lower() == 'no' or train_all_questions_json[question_key]['answer'].lower() == 'yes':\n",
    "        train_all_questions_dict['question_key'] = question_key\n",
    "        #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "        #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "        train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "        train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "        #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "        train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_7.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430536\n"
     ]
    }
   ],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_8.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    if train_all_questions_json[question_key]['answer'].lower() == 'no' or train_all_questions_json[question_key]['answer'].lower() == 'yes':\n",
    "        train_all_questions_dict['question_key'] = question_key\n",
    "        #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "        #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "        train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "        train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "        #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "        train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_8.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430532\n"
     ]
    }
   ],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_9.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    if train_all_questions_json[question_key]['answer'].lower() == 'no' or train_all_questions_json[question_key]['answer'].lower() == 'yes':\n",
    "        train_all_questions_dict['question_key'] = question_key\n",
    "        #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "        #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "        train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "        train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "        #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "        train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_9.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011853\n"
     ]
    }
   ],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/val_all_questions.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    if train_all_questions_json[question_key]['answer'].lower() == 'no' or train_all_questions_json[question_key]['answer'].lower() == 'yes':\n",
    "        train_all_questions_dict['question_key'] = question_key\n",
    "        #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "        #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "        train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "        train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "        #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "        train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "        #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/val_yn_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12874820\n"
     ]
    }
   ],
   "source": [
    "train_all_full_list = []\n",
    "train_all_list = []\n",
    "\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_0.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list = train_all_list\n",
    "    \n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_1.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_2.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_3.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_4.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_5.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_6.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_7.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_8.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_9.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "print (len(train_all_full_list))\n",
    "\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_yn_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_full_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2861072\n"
     ]
    }
   ],
   "source": [
    "train_all_full_list = []\n",
    "train_all_list = []\n",
    "\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_0.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list = train_all_list\n",
    "    \n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_1.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_yn_2.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "print (len(train_all_full_list))\n",
    "\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_yn_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_full_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/python-workdir/VQA_ReGAT/data/gqa/questions/all_answers.pkl\n",
      "/python-workdir/VQA_ReGAT/data/gqa/questions/answers_to_label.pkl\n",
      "/python-workdir/VQA_ReGAT/data/gqa/questions/challenge_all_questions.pkl\n",
      "/python-workdir/VQA_ReGAT/data/gqa/questions/challenge_balanced_questions.pkl\n",
      "/python-workdir/VQA_ReGAT/data/gqa/questions/submission_all_questions.pkl\n",
      "/python-workdir/VQA_ReGAT/data/gqa/questions/test_all_questions.pkl\n",
      "/python-workdir/VQA_ReGAT/data/gqa/questions/test_balanced_questions.pkl\n",
      "/python-workdir/VQA_ReGAT/data/gqa/questions/testdev_all_questions.pkl\n",
      "/python-workdir/VQA_ReGAT/data/gqa/questions/testdev_balanced_questions.pkl\n",
      "/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions.pkl\n",
      "/python-workdir/VQA_ReGAT/data/gqa/questions/train_balanced_questions.pkl\n",
      "/python-workdir/VQA_ReGAT/data/gqa/questions/train_yn_questions.pkl\n",
      "/python-workdir/VQA_ReGAT/data/gqa/questions/val_all_questions.pkl\n",
      "/python-workdir/VQA_ReGAT/data/gqa/questions/val_balanced_questions.pkl\n",
      "/python-workdir/VQA_ReGAT/data/gqa/questions/val_yn_questions.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls /python-workdir/VQA_ReGAT/data/gqa/questions/*.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
