{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_0.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_0.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_0.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_1.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_1.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_2.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_2.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_3.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_3.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_4.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_4.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_5.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_5.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_6.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_6.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_7.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_7.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_8.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_8.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_9.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_9.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/challenge_all_questions.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = None\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/challenge_all_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/challenge_balanced_questions.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = None\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/challenge_balanced_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/challenge_balanced_questions.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = None\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/challenge_balanced_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/submission_all_questions.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = None\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/submission_all_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/testdev_all_questions.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/testdev_all_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/testdev_balanced_questions.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/testdev_balanced_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/test_all_questions.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = None\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/test_all_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/test_balanced_questions.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = None\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/test_balanced_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_balanced_questions.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_balanced_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/val_all_questions.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/val_all_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/val_balanced_questions.json\", \"r\") as train_all_questions:\n",
    "    data = train_all_questions.read()\n",
    "    train_all_questions_json = json.loads(data)\n",
    "    \n",
    "train_all_questions_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    train_all_questions_dict = {}\n",
    "    train_all_questions_dict['question_key'] = question_key\n",
    "    #train_all_questions_dict['entailed_array'] = ','.join(train_all_questions_json[question_key]['entailed'])\n",
    "    #train_all_questions_dict['equivalent_array'] = ','.join(train_all_questions_json[question_key]['equivalent'])\n",
    "    train_all_questions_dict['question'] = train_all_questions_json[question_key]['question']\n",
    "    train_all_questions_dict['image_id'] = train_all_questions_json[question_key]['imageId']\n",
    "    #train_all_questions_dict['is_balanced'] = train_all_questions_json[question_key]['isBalanced']\n",
    "    train_all_questions_dict['answer'] = train_all_questions_json[question_key]['answer']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['semantic_string'] = train_all_questions_json[question_key]['semanticStr']\n",
    "    #train_all_questions_dict['full_answer'] = train_all_questions_json[question_key]['fullAnswer']\n",
    "    train_all_questions_list.append(train_all_questions_dict)\n",
    "    \n",
    "print (len(train_all_questions_list))\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/val_balanced_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_questions_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_full_list = []\n",
    "train_all_list = []\n",
    "\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_0.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list = train_all_list\n",
    "    \n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_1.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_2.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_3.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_4.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_5.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_6.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_7.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_8.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions/train_all_questions_9.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "train_all_full_list.extend(train_all_list)\n",
    "\n",
    "print (len(train_all_full_list))\n",
    "\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_all_questions.pkl\",'wb') as wfp:\n",
    "    pickle.dump(train_all_full_list, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /python-workdir/VQA_ReGAT/data/gqa/questions/*.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_list = []\n",
    "for items in train_all_full_list:\n",
    "    answer = items['answer']\n",
    "    if answer not in answer_list:\n",
    "        answer_list.append(answer)\n",
    "\n",
    "print (len(train_all_full_list))\n",
    "print (len(answer_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/testdev_all_questions.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "\n",
    "for items in train_all_list:\n",
    "    answer = items['answer']\n",
    "    if answer not in answer_list:\n",
    "        answer_list.append(answer)\n",
    "        \n",
    "print (len(answer_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/testdev_balanced_questions.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "\n",
    "for items in train_all_list:\n",
    "    answer = items['answer']\n",
    "    if answer not in answer_list:\n",
    "        answer_list.append(answer)\n",
    "        \n",
    "print (len(answer_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/train_balanced_questions.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "\n",
    "for items in train_all_list:\n",
    "    answer = items['answer']\n",
    "    if answer not in answer_list:\n",
    "        answer_list.append(answer)\n",
    "        \n",
    "print (len(answer_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/val_all_questions.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "\n",
    "for items in train_all_list:\n",
    "    answer = items['answer']\n",
    "    if answer not in answer_list:\n",
    "        answer_list.append(answer)\n",
    "        \n",
    "print (len(answer_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_list.clear()\n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/val_balanced_questions.pkl\",'rb') as rfp:\n",
    "    train_all_list = pickle.load(rfp)\n",
    "\n",
    "for items in train_all_list:\n",
    "    answer = items['answer']\n",
    "    if answer not in answer_list:\n",
    "        answer_list.append(answer)\n",
    "        \n",
    "print (len(answer_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (answer_list[0])\n",
    "print (answer_list[1852])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_label_dict = {}\n",
    "count = 0\n",
    "for answer in answer_list:\n",
    "    answer_label_dict[answer] = count\n",
    "    count = count + 1\n",
    "\n",
    "answer_list = set(answer_list)\n",
    "    \n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/all_answers.pkl\",'wb') as wfp:\n",
    "    pickle.dump(answer_list, wfp)   \n",
    "    \n",
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/answers_to_label.pkl\",'wb') as wfp:\n",
    "    pickle.dump(answer_label_dict, wfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/python-workdir/VQA_ReGAT/data/gqa/questions/answers_to_label.pkl\",'rb') as rfp:\n",
    "    answer_label_dict = pickle.load(rfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_label_dict['green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_semantic_list = []\n",
    "for question_key in train_all_questions_json.keys():\n",
    "    for semantic_dict in train_all_questions_json[question_key]['semantic']:\n",
    "        question_semantic_dict = {}\n",
    "        question_semantic_dict['question_key'] = question_key\n",
    "        question_semantic_dict['operation'] = semantic_dict['operation']\n",
    "        question_semantic_dict['dependencies'] = semantic_dict['dependencies']\n",
    "        question_semantic_dict['argument'] = semantic_dict['argument']\n",
    "        question_semantic_list.append(question_semantic_dict)\n",
    "                                                        \n",
    "question_semantic_df = pd.DataFrame(question_semantic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_semantic_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
